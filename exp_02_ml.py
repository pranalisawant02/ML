# -*- coding: utf-8 -*-
"""Exp_02_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ova1PfRh8FxT34bEw0B_tcpTot1T9AXQ

IMPORT DRIVE
"""

from google.colab import drive
drive.mount('/content/drive')

"""1.LOAD DATASET"""

import numpy as np
import pandas as pd

df=pd.read_csv("/content/drive/MyDrive/ML/housing.csv" )

"""2.DATA EXPLORATION AND PREPROCESSING"""

#Exploration
df.info()

df.describe()

#Printing
print("Missing values before imputation:")
print(df.isnull().sum())

"""-

3.Split Data
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Preview the dataset
print(df.head())

X = df.drop(columns=['median_house_value'])
y = df['median_house_value']

# Split the data: 70% train, 30% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Print shapes to confirm
print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)

"""4. Train Linear Regression Model"""

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import numpy as np

# Identify categorical and numerical columns
categorical_features = ['ocean_proximity']
numerical_features = [col for col in X_train.columns if col not in categorical_features]

# Create a column transformer to apply one-hot encoding to the categorical column and imputation to numerical columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', SimpleImputer(strategy='median'), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough' # Keep other columns (numerical) as they are
)


# Create a pipeline with preprocessing and the Linear Regression model
model = Pipeline(steps=[('preprocessor', preprocessor),
                          ('regressor', LinearRegression())])

# Train the model on the training data
model.fit(X_train, y_train)

print("Linear Regression model trained successfully!")

"""5. Make Predictions"""

# Predict house prices on the test data
y_pred = model.predict(X_test)

# Optional: print first few predictions
print("Predicted values:", y_pred[:5])

"""6. Evaluate Model"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Assuming y_test (true values) and y_pred (predicted values) are defined

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error
rmse = np.sqrt(mse)

# Calculate R² Score
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R²) Score: {r2:.2f}")

"""7. Plot Regression Line"""

import matplotlib.pyplot as plt
import numpy as np

# Choose a single feature to plot
feature_name = 'median_income'

# Extract that feature from X_test and convert to numpy array (just one column)
X_feature = X_test[feature_name].values.reshape(-1, 1)
y_true = y_test.values

# Since we trained on multiple features, let's train a simple linear regression on this single feature to get the line:
from sklearn.linear_model import LinearRegression

# Train model on the single feature from training set
X_feature_train = X_train[feature_name].values.reshape(-1, 1)
y_train_array = y_train.values

simple_lr = LinearRegression()
simple_lr.fit(X_feature_train, y_train_array)

# Predict on the test single feature
y_pred_line = simple_lr.predict(X_feature)

# Plot scatter points of actual data
plt.scatter(X_feature, y_true, color='blue', alpha=0.5, label='Actual data')

# Plot regression line
plt.plot(X_feature, y_pred_line, color='red', linewidth=2, label='Regression line')

plt.xlabel(feature_name)
plt.ylabel('Median House Value')
plt.title(f'Regression Line: {feature_name} vs Median House Value')
plt.legend()
plt.show()

"""8. Plot Residuals"""

import matplotlib.pyplot as plt

# Calculate residuals
residuals = y_pred - y_test

# Plot residuals vs predicted values
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')  # Horizontal line at 0

plt.xlabel('Predicted Values')
plt.ylabel('Residuals (Predicted - Actual)')
plt.title('Residual Plot')
plt.show()